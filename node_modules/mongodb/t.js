// // bulk insert a bunch of data into twitter.tweets
// use twitter;
// var bulk = db.tweets.initializeUnorderedBulkOp(); start = new Date(); for(var i = 0; i < 500000; i++){bulk.insert({"_id" : i, id : new ObjectId()})}; bulk.execute({w:1}); end = new Date(); print(end - start);

// Test app.js

var MongoClient = require('./').MongoClient;
var mongoUrl = 'mongodb://localhost/twitter?maxPoolSize=1';

// MongoClient.connect(mongoUrl, function(err, db) {
//   if (err) return console.error(err);
 
//   var count = 0;
//   var collection = db.collection('tweets');
// // 200k limit seems to be needed to trigger, lesser limits are OK
//   collection.find({}, {"_id" : 0, id : 1}).limit(200000).forEach(function(tweet) {
// // note: setting batch size low, like so triggers the dead cursor messages early
// // collection.find({}, {"_id" : 0, id : 1}).batchSize(8000).limit(200000).forEach(function(tweet) {
// // otherwise it errors when it hits the 4MiB limit (see log lines from mongod later)
//     // console.log(tweet.id);
//     console.log(count++)
//   }, function(err) {
//     if (err) console.error(err);
//     db.close();
//     process.exit(0)
//   });
// }); 

var d = new Date().getTime();
MongoClient.connect(mongoUrl, function(err, db) {
  if (err) return console.error(err);
 
  var count = 0;
  var errcount = 0;
  var collection = db.collection('tweets');
  var cursor = collection.find({}, {"_id" : 0, id : 1});
  cursor
    .limit(200000)
    // .limit(1000)
    .batchSize(200000)
    // .batchSize(41000)
    // .batchSize(1000)
    .each(function(err, docs) {
      // if(docs) console.log(count++)
      if (err) { 
        console.log("------------------------- err")
        console.error(err); 
      }
      if (docs == null) {
        console.log("------------------------- close")
        console.log("time :: " + (new Date().getTime() - d))
        db.close();
        // process.exit(0);        
      };
  });
});
// MongoClient.connect(mongoUrl, function(err, db) {
//   if (err) return console.error(err);
//   // console.dir("------------")
//   var collection = db.collection('tweets');
//   var count = 0;
// // 200k limit seems to be needed to trigger, lesser limits are OK
//   var s = new Date();
//   // collection.find({}, {"_id" : 0, id : 1})
//   // .limit(200000)
//   // .batchSize(1000)
//   // .each(function(err, tweet) {
//   //   if(err) throw err;
//   //   if(tweet == null) {
//   //     console.log("---------- close")
//   //     db.close();
//   // console.log(" time = " + (new Date().getTime() - s.getTime()))
//   //     process.exit(0);
//   //   } else {
//   //     // console.log(count++)
//   //   }
//   //   // console.log(tweet)
//   //   // console.log(tweet.id);
//   // });

//   collection.find({}, {"_id" : 0, id : 1})
//   // .limit(10000)
//   .limit(200000)
//   // .batchSize(1)
//   .forEach(function(tweet) {
//     // console.log(tweet.id);
//     // console.log(count++)
//   }, function(err) {
//   console.log(" time = " + (new Date().getTime() - s.getTime()))
//     if (err) console.error(err);
//     db.close();
//     process.exit(0);
//   });
// }); 